#+TITLE: HN Digest 2026-01-14 11:00:00 UT UTC
#+DATE: 2026-01-14T11:00:00Z
#+CURATOR: claude
#+SOURCE: https://hacker-news.firebaseio.com/v0/

* Vibe
Cards with no rules, languages with all the types, and Redis gets dumped for a database it never saw coming

* Highlights
- 1000 Blank White Cards: The game where making up rules IS the game
- Gleam: Type safety meets Erlang's indestructible runtime
- Rails dumps Redis for PostgreSQL in a classic 'we had it at home' move
- vLLM squeezes 2.2k tokens/sec from H200s running DeepSeek
- Natural language interfaces: maybe just use buttons?

* Stories

** 1000 Blank White Cards :games:creativity:meta:
:PROPERTIES:
:ID:       46611823
:URL:      https://en.wikipedia.org/wiki/1000_Blank_White_Cards
:HN_URL:   https://news.ycombinator.com/item?id=46611823
:POINTS:   184
:COMMENTS: 30
:BY:       eieio
:END:

*** TLDR
A 1995 party game where players create cards and rules during play. You start with blank cards, draw pictures and write effects on them, then shuffle them together and play. The real victory isn't points - it's having your cards deemed worthy of keeping for next time.

*** Take
Finally, a game that accurately simulates working at a startup where the rules change every sprint and nobody knows who's winning.

*** Comments

**** voidUpdate
:PROPERTIES:
:COMMENT_ID: 46612001
:END:
There's a british comedy radio show called 'I'm Sorry I Haven't A Clue' that plays 'Mornington Crescent', which is similar - comedians listing off London tube stations until one says 'Mornington Crescent'.

**** Qmppu842
:PROPERTIES:
:COMMENT_ID: 46612102
:END:
I came across Mao, a game with hidden rules. Since I had read about it on Wikipedia we didn't have culture to base it on. It morphed into basically Uno where the winner gets to make new rules.

**** kiwih
:PROPERTIES:
:COMMENT_ID: 46612203
:END:
There's a drinking game called 'Pizza Box' inspired by this. You flip a coin into an empty pizza box, and if it lands on a blank spot you draw a new rule there.

*** i18n                                                  :i18n:

**** zh
:PROPERTIES:
:LANG: zh
:END:
***** Title
1000张空白卡
***** TLDR
一款1995年的派对游戏，玩家在游戏过程中创造卡牌和规则。从空白卡开始，画图写效果，洗牌后一起玩。真正的胜利不是得分，而是让你的卡被认为值得保留到下次。
***** Take
终于有一款游戏准确模拟了在创业公司工作的感觉：规则每个冲刺都在变，没人知道谁在赢。
***** Comments
- 英国有个喜剧广播节目叫《对不起我没有线索》，玩一个叫'莫宁顿新月'的游戏，类似这个——喜剧演员轮流说伦敦地铁站名，直到有人说'莫宁顿新月'。
- 我发现了Mao这个有隐藏规则的游戏。因为我在维基百科上读过，我们没有文化基础。它演变成了基本版的Uno，获胜者可以制定新规则。
- 有个叫'披萨盒'的酒桌游戏受此启发。你把硬币扔进空披萨盒，如果落在空白处就在那画一条新规则。
**** ja
:PROPERTIES:
:LANG: ja
:END:
***** Title
1000枚の白紙カード
***** TLDR
1995年のパーティーゲームで、プレイヤーがプレイ中にカードとルールを作成。白紙カードから始め、絵を描いて効果を書き、シャッフルして遊ぶ。本当の勝利はポイントではなく、次回のために残す価値があると認められたカード。
***** Take
ついに、スタートアップで働く感覚を正確にシミュレートするゲームが登場。ルールは毎スプリント変わり、誰が勝っているかは誰も知らない。
***** Comments
- イギリスのコメディラジオ番組『I'm Sorry I Haven't A Clue』で『モーニントン・クレセント』というゲームをやっている。似たようなもので、コメディアンがロンドンの地下鉄駅名を言い続け、誰かが『モーニントン・クレセント』と言うまで続く。
- 隠しルールのあるMaoというゲームを見つけた。Wikipediaで読んだので文化的基盤がなかった。基本的にUnoになり、勝者が新しいルールを作れるようになった。
- これにインスパイアされた『ピザボックス』という飲み会ゲームがある。空のピザ箱にコインを投げ、空白部分に落ちたら新しいルールを書く。
**** ko
:PROPERTIES:
:LANG: ko
:END:
***** Title
1000장의 빈 흰 카드
***** TLDR
1995년 파티 게임으로 플레이어가 게임 중에 카드와 규칙을 만든다. 빈 카드로 시작해서 그림을 그리고 효과를 쓴 다음, 섞어서 함께 플레이한다. 진정한 승리는 점수가 아니라 다음 게임을 위해 보관할 가치가 있다고 인정받는 것이다.
***** Take
드디어 스타트업에서 일하는 경험을 정확히 시뮬레이션하는 게임이 나왔다. 규칙은 매 스프린트마다 바뀌고 누가 이기고 있는지 아무도 모른다.
***** Comments
- 영국 코미디 라디오 쇼 'I'm Sorry I Haven't A Clue'에서 '모닝턴 크레센트'라는 비슷한 게임을 한다. 코미디언들이 런던 지하철역 이름을 말하다가 누군가 '모닝턴 크레센트'라고 말하면 끝난다.
- 숨겨진 규칙이 있는 Mao라는 게임을 발견했다. 위키피디아에서 읽었기 때문에 문화적 기반이 없었다. 기본적으로 우노가 되어 승자가 새 규칙을 만들 수 있게 되었다.
- 이것에서 영감받은 '피자 박스'라는 음주 게임이 있다. 빈 피자 박스에 동전을 던지고 빈 곳에 떨어지면 새 규칙을 그린다.
**** es
:PROPERTIES:
:LANG: es
:END:
***** Title
1000 Cartas Blancas en Blanco
***** TLDR
Un juego de fiesta de 1995 donde los jugadores crean cartas y reglas durante el juego. Empiezas con cartas en blanco, dibujas y escribes efectos, luego las mezclas y juegas. La verdadera victoria no son los puntos, sino que tus cartas sean consideradas dignas de guardar para la próxima vez.
***** Take
Por fin un juego que simula con precisión trabajar en una startup donde las reglas cambian cada sprint y nadie sabe quién va ganando.
***** Comments
- Hay un programa de comedia de radio británico llamado 'I'm Sorry I Haven't A Clue' que juega a 'Mornington Crescent', similar a esto - comediantes diciendo estaciones del metro de Londres hasta que alguien dice 'Mornington Crescent'.
- Encontré Mao, un juego con reglas ocultas. Como lo leí en Wikipedia no teníamos cultura base. Se transformó básicamente en Uno donde el ganador puede crear nuevas reglas.
- Hay un juego de beber llamado 'Pizza Box' inspirado en esto. Lanzas una moneda en una caja de pizza vacía, y si cae en un espacio en blanco dibujas una nueva regla ahí.
**** de
:PROPERTIES:
:LANG: de
:END:
***** Title
1000 Leere Weiße Karten
***** TLDR
Ein Partyspiel von 1995, bei dem Spieler während des Spiels Karten und Regeln erstellen. Man beginnt mit leeren Karten, zeichnet Bilder und schreibt Effekte, mischt sie dann und spielt. Der wahre Sieg sind nicht Punkte, sondern dass deine Karten als würdig erachtet werden, für das nächste Mal aufbewahrt zu werden.
***** Take
Endlich ein Spiel, das die Arbeit in einem Startup akkurat simuliert, wo sich die Regeln jeden Sprint ändern und niemand weiß, wer gewinnt.
***** Comments
- Es gibt eine britische Comedy-Radiosendung namens 'I'm Sorry I Haven't A Clue', die 'Mornington Crescent' spielt - Comedians nennen Londoner U-Bahn-Stationen, bis einer 'Mornington Crescent' sagt.
- Ich fand Mao, ein Spiel mit versteckten Regeln. Da ich es auf Wikipedia gelesen hatte, hatten wir keine Kulturbasis. Es wurde im Grunde zu Uno, wo der Gewinner neue Regeln machen kann.
- Es gibt ein Trinkspiel namens 'Pizza Box', das davon inspiriert ist. Man wirft eine Münze in einen leeren Pizzakarton, und wenn sie auf einer leeren Stelle landet, zeichnet man dort eine neue Regel.
** The Gleam Programming Language :programming-languages:erlang:functional:
:PROPERTIES:
:ID:       46611667
:URL:      https://gleam.run/
:HN_URL:   https://news.ycombinator.com/item?id=46611667
:POINTS:   143
:COMMENTS: 77
:BY:       Alupis
:END:

*** TLDR
Gleam is a statically-typed functional language that runs on the Erlang VM (BEAM) or compiles to JavaScript. It gives you Erlang's legendary fault tolerance and concurrency with actual type safety, no nulls, and clear error messages.

*** Take
It's what happens when Erlang and TypeScript have a baby and that baby grows up to be responsible. HN commenters are torn between 'no macros bad' and 'we use this in production and it's amazing'.

*** Comments

**** pkos98
:PROPERTIES:
:COMMENT_ID: 46612301
:END:
Coming from Elixir, I gave Gleam a try. Reasons I decided not to pursue: No ad-hoc polymorphism means no standard way of defining how things work. Coupled with a lack of macros, this means you won't know if your library supports JSON deserialization.

**** lexx
:PROPERTIES:
:COMMENT_ID: 46612402
:END:
Gleam is ready and is amazing. We use Gleam as the main language in our company.

**** heliumtera
:PROPERTIES:
:COMMENT_ID: 46612503
:END:
One of the best things about Erlang/Elixir is REPL-driven development. Gleam has no interpreted story, right? What is the debugging mindset without inspect() or dbg()?

*** i18n                                                  :i18n:

**** zh
:PROPERTIES:
:LANG: zh
:END:
***** Title
Gleam编程语言
***** TLDR
Gleam是一种静态类型的函数式语言，运行在Erlang虚拟机(BEAM)上或编译成JavaScript。它提供了Erlang传奇的容错性和并发性，同时具有真正的类型安全、无空值和清晰的错误信息。
***** Take
这就是当Erlang和TypeScript生了个孩子，而这个孩子长大后变得很负责任时会发生的事。HN评论者在'没有宏不好'和'我们在生产中使用它很棒'之间犹豫不决。
***** Comments
- 从Elixir过来，我试了试Gleam。决定不继续的原因：没有临时多态意味着没有定义事物工作方式的标准方法。加上缺乏宏，这意味着你不知道你的库是否支持JSON反序列化。
- Gleam已经准备好了，非常棒。我们公司用Gleam作为主要语言。
- Erlang/Elixir最好的一点是REPL驱动开发。Gleam没有解释执行吧？没有inspect()或dbg()怎么调试？
**** ja
:PROPERTIES:
:LANG: ja
:END:
***** Title
Gleamプログラミング言語
***** TLDR
Gleamは、Erlang VM（BEAM）で動作するか、JavaScriptにコンパイルされる静的型付け関数型言語。Erlangの伝説的な耐障害性と並行性を、本物の型安全性、null無し、明確なエラーメッセージと共に提供する。
***** Take
ErlangとTypeScriptに子供ができて、その子供が責任感のある大人に育ったらこうなる。HNのコメンターは「マクロがないのは悪い」と「本番で使っていて素晴らしい」の間で揺れている。
***** Comments
- Elixirから来て、Gleamを試してみた。追求しないことにした理由：アドホック多態性がないということは、物事の動作を定義する標準的な方法がないということ。マクロの欠如と相まって、ライブラリがJSON逆シリアル化をサポートしているかわからない。
- Gleamは準備ができていて素晴らしい。私たちの会社ではGleamをメイン言語として使っている。
- Erlang/Elixirの最も良い点の一つはREPL駆動開発だ。Gleamにはインタープリタがないよね？inspect()やdbg()なしでのデバッグの考え方は？
**** ko
:PROPERTIES:
:LANG: ko
:END:
***** Title
Gleam 프로그래밍 언어
***** TLDR
Gleam은 Erlang VM(BEAM)에서 실행되거나 JavaScript로 컴파일되는 정적 타입 함수형 언어이다. Erlang의 전설적인 내결함성과 동시성을 실제 타입 안전성, null 없음, 명확한 오류 메시지와 함께 제공한다.
***** Take
Erlang과 TypeScript가 아이를 낳고 그 아이가 책임감 있는 어른으로 자라면 이렇게 된다. HN 댓글러들은 '매크로 없음 나쁨'과 '프로덕션에서 쓰는데 대단함' 사이에서 갈등 중이다.
***** Comments
- Elixir에서 와서 Gleam을 며칠 시도해봤다. 포기한 이유: 임시 다형성이 없다는 것은 작동 방식을 정의하는 표준 방법이 없다는 것을 의미한다. 매크로 부족과 결합하면 라이브러리가 JSON 역직렬화를 지원하는지 알 수 없다.
- Gleam은 준비됐고 놀랍다. 우리 회사에서 Gleam을 메인 언어로 쓴다.
- Erlang/Elixir의 가장 좋은 점 중 하나는 REPL 기반 개발이다. Gleam에는 인터프리터가 없지 않나? inspect()나 dbg() 없이 디버깅 마인드셋은 어떻게 되나?
**** es
:PROPERTIES:
:LANG: es
:END:
***** Title
El Lenguaje de Programación Gleam
***** TLDR
Gleam es un lenguaje funcional con tipos estáticos que corre en la VM de Erlang (BEAM) o compila a JavaScript. Te da la legendaria tolerancia a fallos y concurrencia de Erlang con verdadera seguridad de tipos, sin nulos y mensajes de error claros.
***** Take
Es lo que pasa cuando Erlang y TypeScript tienen un bebé y ese bebé crece para ser responsable. Los comentaristas de HN están divididos entre 'sin macros malo' y 'lo usamos en producción y es increíble'.
***** Comments
- Viniendo de Elixir, probé Gleam. Razones por las que decidí no continuar: Sin polimorfismo ad-hoc significa que no hay forma estándar de definir cómo funcionan las cosas. Junto con la falta de macros, esto significa que no sabrás si tu librería soporta deserialización JSON.
- Gleam está listo y es increíble. Usamos Gleam como lenguaje principal en nuestra empresa.
- Una de las mejores cosas de Erlang/Elixir es el desarrollo dirigido por REPL. Gleam no tiene modo interpretado, ¿verdad? ¿Cuál es la mentalidad de depuración sin inspect() o dbg()?
**** de
:PROPERTIES:
:LANG: de
:END:
***** Title
Die Gleam Programmiersprache
***** TLDR
Gleam ist eine statisch typisierte funktionale Sprache, die auf der Erlang VM (BEAM) läuft oder zu JavaScript kompiliert. Sie bietet Erlangs legendäre Fehlertoleranz und Nebenläufigkeit mit echter Typsicherheit, ohne Nullwerte und mit klaren Fehlermeldungen.
***** Take
Das passiert, wenn Erlang und TypeScript ein Kind bekommen und dieses Kind verantwortungsbewusst aufwächst. HN-Kommentatoren sind hin- und hergerissen zwischen 'keine Makros schlecht' und 'wir benutzen es in Produktion und es ist großartig'.
***** Comments
- Von Elixir kommend, habe ich Gleam ausprobiert. Gründe, warum ich nicht weitermachte: Kein Ad-hoc-Polymorphismus bedeutet keine Standardmethode zu definieren, wie Dinge funktionieren. Gepaart mit fehlenden Makros bedeutet das, dass man nicht weiß, ob die Bibliothek JSON-Deserialisierung unterstützt.
- Gleam ist bereit und großartig. Wir verwenden Gleam als Hauptsprache in unserem Unternehmen.
- Einer der besten Aspekte von Erlang/Elixir ist REPL-getriebene Entwicklung. Gleam hat keine interpretierte Geschichte, oder? Wie ist die Debugging-Mentalität ohne inspect() oder dbg()?
** I Love You, Redis, but I'm Leaving You for SolidQueue :rails:redis:postgresql:infrastructure:
:PROPERTIES:
:ID:       46614037
:URL:      https://www.simplethread.com/redis-solidqueue/
:HN_URL:   https://news.ycombinator.com/item?id=46614037
:POINTS:   46
:COMMENTS: 17
:BY:       amalinovic
:END:

*** TLDR
Rails 8 ditches Redis for SolidQueue, which uses PostgreSQL's FOR UPDATE SKIP LOCKED to handle job queues. You get concurrency limits, recurring jobs, and monitoring dashboard for free. Works for 99% of apps doing under 300 jobs/sec.

*** Take
Redis and Sidekiq solve a problem you don't have at a cost you can't afford. The antirez cameo in the comments being chill about it is peak open source maturity.

*** Comments

**** antirez
:PROPERTIES:
:COMMENT_ID: 46614101
:END:
Every time some production environment can be simplified, it is good news. The ideal situation with Rails would be if there is a simple way to switch back to Redis when you hit scalability issues.

**** victorbjorklund
:PROPERTIES:
:COMMENT_ID: 46614202
:END:
For people that don't think it scales: Oban in Elixir benchmarks a million jobs per minute on a single node. I bet 99.99999% of apps have less than a million background jobs per minute.

**** rajaravivarma_r
:PROPERTIES:
:COMMENT_ID: 46614303
:END:
The one use case where a DB backed queue will fail is when the payload is large. I've benchmarked Redis (Sidekiq), Postgres (GoodJob) and SQLite (SolidQueue) - Redis beats everything for large JSON payloads.

*** i18n                                                  :i18n:

**** zh
:PROPERTIES:
:LANG: zh
:END:
***** Title
我爱你Redis，但我要离开你去SolidQueue了
***** TLDR
Rails 8放弃Redis改用SolidQueue，它使用PostgreSQL的FOR UPDATE SKIP LOCKED来处理作业队列。你免费获得并发限制、定时任务和监控面板。适用于99%处理每秒300个以下作业的应用。
***** Take
Redis和Sidekiq解决了你没有的问题，花费了你承担不起的成本。antirez在评论区淡定回应，这才是开源成熟度的巅峰。
***** Comments
- 每当生产环境可以简化时，都是好消息。Rails的理想情况是当你遇到扩展性问题时有简单的方法切换回Redis。
- 对于认为它不能扩展的人：Elixir中的Oban在单节点上每分钟处理一百万个作业。我敢打赌99.99999%的应用每分钟的后台作业不到一百万。
- 数据库支持的队列会失败的一个场景是当载荷很大时。我测试过Redis（Sidekiq）、Postgres（GoodJob）和SQLite（SolidQueue）——对于大型JSON载荷，Redis完胜。
**** ja
:PROPERTIES:
:LANG: ja
:END:
***** Title
愛してるRedis、でもSolidQueueに行くよ
***** TLDR
Rails 8はRedisを捨ててSolidQueueを採用。PostgreSQLのFOR UPDATE SKIP LOCKEDでジョブキューを処理する。同時実行制限、定期ジョブ、監視ダッシュボードが無料で付いてくる。秒間300ジョブ以下の99%のアプリに対応。
***** Take
RedisとSidekiqは、あなたにはない問題を、払えないコストで解決している。コメント欄でantirezが冷静に対応しているのが、オープンソース成熟度の極み。
***** Comments
- 本番環境が簡素化できるたびに、それは良いニュースだ。Railsの理想は、スケーラビリティの問題にぶつかった時にRedisに簡単に切り替えられること。
- スケールしないと思う人へ：ElixirのObanは単一ノードで1分間に100万ジョブをベンチマークしている。99.99999%のアプリは1分間に100万のバックグラウンドジョブもないはず。
- DBバックエンドキューが失敗するケースは、ペイロードが大きい時。Redis（Sidekiq）、Postgres（GoodJob）、SQLite（SolidQueue）をベンチマークしたが、大きなJSONペイロードではRedisが全てに勝つ。
**** ko
:PROPERTIES:
:LANG: ko
:END:
***** Title
사랑해 Redis, 하지만 SolidQueue로 떠날게
***** TLDR
Rails 8이 Redis를 버리고 SolidQueue를 채택했다. PostgreSQL의 FOR UPDATE SKIP LOCKED로 작업 큐를 처리한다. 동시성 제한, 반복 작업, 모니터링 대시보드가 무료로 제공된다. 초당 300개 미만의 작업을 처리하는 99%의 앱에 적합하다.
***** Take
Redis와 Sidekiq는 당신이 없는 문제를 감당할 수 없는 비용으로 해결한다. 댓글에서 antirez가 담담하게 반응하는 게 오픈소스 성숙함의 정점이다.
***** Comments
- 프로덕션 환경이 단순화될 때마다 좋은 소식이다. Rails의 이상적인 상황은 확장성 문제에 부딪혔을 때 Redis로 쉽게 전환할 수 있는 것이다.
- 확장 안 된다고 생각하는 사람들에게: Elixir의 Oban은 단일 노드에서 분당 백만 개의 작업을 벤치마크한다. 99.99999%의 앱은 분당 백만 개의 백그라운드 작업도 없을 거다.
- DB 기반 큐가 실패하는 경우는 페이로드가 클 때다. Redis(Sidekiq), Postgres(GoodJob), SQLite(SolidQueue)를 벤치마크했는데 - 큰 JSON 페이로드에서는 Redis가 모든 것을 이긴다.
**** es
:PROPERTIES:
:LANG: es
:END:
***** Title
Te Amo Redis, pero Me Voy con SolidQueue
***** TLDR
Rails 8 abandona Redis por SolidQueue, que usa FOR UPDATE SKIP LOCKED de PostgreSQL para manejar colas de trabajo. Obtienes límites de concurrencia, trabajos recurrentes y panel de monitoreo gratis. Funciona para el 99% de apps con menos de 300 trabajos/seg.
***** Take
Redis y Sidekiq resuelven un problema que no tienes a un costo que no puedes pagar. El cameo de antirez en los comentarios siendo relajado al respecto es la cima de la madurez open source.
***** Comments
- Cada vez que un entorno de producción puede simplificarse, son buenas noticias. La situación ideal con Rails sería tener una forma simple de volver a Redis cuando tengas problemas de escalabilidad.
- Para los que piensan que no escala: Oban en Elixir hace benchmark de un millón de trabajos por minuto en un solo nodo. Apuesto que el 99.99999% de las apps tienen menos de un millón de trabajos de fondo por minuto.
- El caso donde una cola respaldada por DB fallará es cuando el payload es grande. He hecho benchmarks de Redis (Sidekiq), Postgres (GoodJob) y SQLite (SolidQueue) - Redis gana en todo para payloads JSON grandes.
**** de
:PROPERTIES:
:LANG: de
:END:
***** Title
Ich Liebe Dich Redis, aber Ich Gehe zu SolidQueue
***** TLDR
Rails 8 ersetzt Redis durch SolidQueue, das PostgreSQLs FOR UPDATE SKIP LOCKED für Job-Queues nutzt. Du bekommst Concurrency-Limits, wiederkehrende Jobs und Monitoring-Dashboard kostenlos. Funktioniert für 99% der Apps unter 300 Jobs/Sek.
***** Take
Redis und Sidekiq lösen ein Problem, das du nicht hast, zu Kosten, die du dir nicht leisten kannst. Dass antirez in den Kommentaren so entspannt reagiert, ist der Höhepunkt von Open-Source-Reife.
***** Comments
- Jedes Mal, wenn eine Produktionsumgebung vereinfacht werden kann, sind das gute Nachrichten. Die ideale Situation mit Rails wäre, wenn es einen einfachen Weg gibt, zu Redis zurückzuwechseln, wenn Skalierungsprobleme auftreten.
- Für Leute, die denken, es skaliert nicht: Oban in Elixir benchmarkt eine Million Jobs pro Minute auf einem einzelnen Knoten. Ich wette, 99,99999% der Apps haben weniger als eine Million Hintergrund-Jobs pro Minute.
- Der eine Anwendungsfall, wo eine DB-gestützte Queue versagt, ist bei großen Payloads. Ich habe Redis (Sidekiq), Postgres (GoodJob) und SQLite (SolidQueue) gebenchmarkt - Redis schlägt alles bei großen JSON-Payloads.
** vLLM large scale serving: DeepSeek 2.2k tok/s/H200 with wide-ep :llm:infrastructure:performance:gpu:
:PROPERTIES:
:ID:       46602737
:URL:      https://blog.vllm.ai/2025/12/17/large-scale-serving.html
:HN_URL:   https://news.ycombinator.com/item?id=46602737
:POINTS:   110
:COMMENTS: 29
:BY:       robertnishihara
:END:

*** TLDR
vLLM achieved 2.2k tokens/second per H200 GPU serving DeepSeek-V3 using Wide Expert Parallelism, Dual-Batch Overlap, and disaggregated serving. On a 16xH200 cluster ($750k hardware), this translates to roughly $4 per million tokens over 3 years.

*** Take
Someone did the actual math in the comments: 63 billion tokens over 3 years at $4/million. That's cheaper than my coffee habit and infinitely more productive.

*** Comments

**** rbanffy
:PROPERTIES:
:COMMENT_ID: 46603001
:END:
Very impressive numbers - I'd expect 2K tok/s on Cerebras hardware, not H200s.

**** dust42
:PROPERTIES:
:COMMENT_ID: 46603102
:END:
If I followed the links correctly this benchmark was made on 16xH200. At current prices that's around $750,000. The year has 31536000 seconds. Thus 63 billion tokens can be generated. Write off over 3 years: $4/million tokens.

**** kingstnap
:PROPERTIES:
:COMMENT_ID: 46603203
:END:
Impressive performance work. It's interesting that you still see these 40+% perf gains. Makes you think the costs for a fixed level of 'intelligence' will keep dropping.

*** i18n                                                  :i18n:

**** zh
:PROPERTIES:
:LANG: zh
:END:
***** Title
vLLM大规模服务：使用wide-ep在每个H200上实现DeepSeek 2.2k tok/s
***** TLDR
vLLM使用宽专家并行、双批次重叠和分离式服务，在H200 GPU上实现了每秒2.2k tokens的DeepSeek-V3服务。在16个H200集群（75万美元硬件）上，这相当于3年内每百万tokens约4美元。
***** Take
有人在评论里算了笔账：3年630亿tokens，每百万4美元。这比我的咖啡习惯还便宜，而且效率高得多。
***** Comments
- 非常令人印象深刻的数字——我以为2K tok/s需要Cerebras硬件，没想到H200也能做到。
- 如果我没看错的话，这个基准测试是在16个H200上做的。按当前价格大约75万美元。一年有3153.6万秒。因此可以生成630亿tokens。分摊3年：每百万tokens 4美元。
- 令人印象深刻的性能工作。有趣的是你仍然能看到这些40%以上的性能提升。这让人觉得固定'智能'水平的成本会持续下降。
**** ja
:PROPERTIES:
:LANG: ja
:END:
***** Title
vLLM大規模サービング：wide-epでH200あたりDeepSeek 2.2k tok/s
***** TLDR
vLLMはWide Expert Parallelism、Dual-Batch Overlap、分離サービングを使用して、H200 GPUでDeepSeek-V3の秒間2.2kトークンを達成。16台のH200クラスター（75万ドルのハードウェア）で、3年間で100万トークンあたり約4ドルになる。
***** Take
コメントで誰かが実際に計算した：3年間で630億トークン、100万あたり4ドル。私のコーヒー習慣より安くて、はるかに生産的だ。
***** Comments
- 非常に印象的な数字 - 2K tok/sはCerebrasハードウェアで期待する数字で、H200ではない。
- リンクを正しく追ったなら、このベンチマークは16台のH200で行われた。現在の価格で約75万ドル。1年は3153万6000秒。つまり630億トークンを生成できる。3年で償却：100万トークンあたり4ドル。
- 印象的なパフォーマンス作業。40%以上の性能向上がまだ見られるのは興味深い。固定レベルの「知性」のコストが下がり続けると思わせる。
**** ko
:PROPERTIES:
:LANG: ko
:END:
***** Title
vLLM 대규모 서빙: wide-ep로 H200당 DeepSeek 2.2k tok/s
***** TLDR
vLLM은 Wide Expert Parallelism, Dual-Batch Overlap, 분리 서빙을 사용하여 H200 GPU에서 DeepSeek-V3를 초당 2.2k 토큰으로 서빙했다. 16대의 H200 클러스터(75만 달러 하드웨어)에서 3년간 백만 토큰당 약 4달러로 계산된다.
***** Take
댓글에서 누군가 실제로 계산했다: 3년간 630억 토큰, 백만당 4달러. 내 커피 습관보다 저렴하고 무한히 더 생산적이다.
***** Comments
- 매우 인상적인 수치다 - 2K tok/s는 Cerebras 하드웨어에서 기대하는 수준이지, H200이 아니다.
- 링크를 제대로 따라갔다면 이 벤치마크는 16대의 H200에서 수행됐다. 현재 가격으로 약 75만 달러. 1년은 3153만 6000초다. 따라서 630억 토큰을 생성할 수 있다. 3년 상각: 백만 토큰당 4달러.
- 인상적인 성능 작업이다. 여전히 40% 이상의 성능 향상을 보는 것이 흥미롭다. 고정된 수준의 '지능'에 대한 비용이 계속 떨어질 것 같은 생각이 든다.
**** es
:PROPERTIES:
:LANG: es
:END:
***** Title
vLLM servicio a gran escala: DeepSeek 2.2k tok/s/H200 con wide-ep
***** TLDR
vLLM logró 2.2k tokens/segundo por GPU H200 sirviendo DeepSeek-V3 usando Wide Expert Parallelism, Dual-Batch Overlap y servicio desagregado. En un clúster de 16xH200 (hardware de $750k), esto se traduce en aproximadamente $4 por millón de tokens en 3 años.
***** Take
Alguien hizo las matemáticas reales en los comentarios: 63 mil millones de tokens en 3 años a $4/millón. Eso es más barato que mi hábito de café e infinitamente más productivo.
***** Comments
- Números muy impresionantes - esperaría 2K tok/s en hardware Cerebras, no en H200s.
- Si seguí los enlaces correctamente, este benchmark se hizo en 16xH200. A precios actuales eso es alrededor de $750,000. El año tiene 31,536,000 segundos. Así que se pueden generar 63 mil millones de tokens. Amortizado en 3 años: $4/millón de tokens.
- Trabajo de rendimiento impresionante. Es interesante que todavía se vean ganancias de rendimiento del 40%+. Hace pensar que los costos para un nivel fijo de 'inteligencia' seguirán bajando.
**** de
:PROPERTIES:
:LANG: de
:END:
***** Title
vLLM Großserving: DeepSeek 2.2k tok/s/H200 mit wide-ep
***** TLDR
vLLM erreichte 2,2k Tokens/Sekunde pro H200 GPU beim Serving von DeepSeek-V3 mit Wide Expert Parallelism, Dual-Batch Overlap und disaggregiertem Serving. Auf einem 16xH200-Cluster ($750k Hardware) entspricht das etwa $4 pro Million Tokens über 3 Jahre.
***** Take
Jemand hat in den Kommentaren tatsächlich gerechnet: 63 Milliarden Tokens über 3 Jahre bei $4/Million. Das ist billiger als meine Kaffeegewohnheit und unendlich produktiver.
***** Comments
- Sehr beeindruckende Zahlen - ich hätte 2K tok/s auf Cerebras-Hardware erwartet, nicht auf H200s.
- Wenn ich den Links richtig gefolgt bin, wurde dieser Benchmark auf 16xH200 gemacht. Bei aktuellen Preisen sind das etwa $750.000. Das Jahr hat 31.536.000 Sekunden. So können 63 Milliarden Tokens generiert werden. Über 3 Jahre abgeschrieben: $4/Million Tokens.
- Beeindruckende Leistungsarbeit. Es ist interessant, dass man immer noch diese 40%+ Leistungsgewinne sieht. Lässt einen denken, dass die Kosten für ein festes Niveau an 'Intelligenz' weiter sinken werden.
** Stop using natural language interfaces :ai:ux:llm:design:
:PROPERTIES:
:ID:       46611550
:URL:      https://tidepool.leaflet.pub/3mcbegnuf2k2i
:HN_URL:   https://news.ycombinator.com/item?id=46611550
:POINTS:   82
:COMMENTS: 36
:BY:       steveklabnik
:END:

*** TLDR
Natural language interfaces via LLMs have terrible latency - often tens of seconds. The author proposes a hybrid approach: use structured UI elements (dropdowns, checkboxes) with an 'Other' escape hatch for flexibility. Best of both worlds.

*** Take
Hot take that will make half of YC Demo Day cry: maybe your chatbot should just be a form. Revolutionary, I know.

*** Comments

**** rimesforfree
:PROPERTIES:
:COMMENT_ID: 46611701
:END:
I get that you want to save the world by reducing processing, but 'stop using natural language interfaces' is overly restrictive. Interactive fiction from the 20th century used deterministic natural language with low load as an intentional design.

**** your_friend
:PROPERTIES:
:COMMENT_ID: 46611802
:END:
I think text interface sucks, but at the same time I like how Claude Code solves that with questionnaires. That's the most elegant solution to get valuable context from users fast.

**** kami23
:PROPERTIES:
:COMMENT_ID: 46611903
:END:
Love this, this is what I have been envisioning as an LLM-first OS! The idea of having elements anticipated and lowering the cognitive load of searching a giant dropdown scratches a good place in my brain.

*** i18n                                                  :i18n:

**** zh
:PROPERTIES:
:LANG: zh
:END:
***** Title
停止使用自然语言界面
***** TLDR
通过LLM的自然语言界面延迟很高——通常需要几十秒。作者提出了一种混合方法：使用结构化UI元素（下拉菜单、复选框）并保留'其他'选项以保持灵活性。两全其美。
***** Take
会让半个YC Demo Day哭泣的热辣观点：也许你的聊天机器人应该只是一个表单。革命性的，我知道。
***** Comments
- 我理解你想通过减少处理来拯救世界，但'停止使用自然语言界面'过于限制性。20世纪的互动小说使用低负载的确定性自然语言作为有意的设计。
- 我觉得文字界面很糟糕，但同时我喜欢Claude Code用问卷解决这个问题的方式。这是快速从用户获取有价值上下文的最优雅解决方案。
- 喜欢这个，这就是我一直设想的LLM优先操作系统！预先准备好元素并降低搜索巨大下拉列表的认知负担，这正中我意。
**** ja
:PROPERTIES:
:LANG: ja
:END:
***** Title
自然言語インターフェースの使用をやめよう
***** TLDR
LLMを介した自然言語インターフェースはレイテンシがひどい - 数十秒かかることも。著者はハイブリッドアプローチを提案：構造化されたUI要素（ドロップダウン、チェックボックス）に「その他」のエスケープハッチを用意して柔軟性を確保。両方のいいとこ取り。
***** Take
YC Demo Dayの半分を泣かせるホットテイク：たぶんチャットボットはただのフォームであるべきだ。革命的だろ、知ってる。
***** Comments
- 処理を減らして世界を救いたいのはわかるが、「自然言語インターフェースをやめろ」は過度に制限的だ。20世紀のインタラクティブフィクションは、意図的なデザインとして低負荷の決定論的自然言語を使っていた。
- テキストインターフェースはダメだと思うが、同時にClaude Codeがアンケートで解決する方法が好きだ。ユーザーから価値ある文脈を素早く得る最もエレガントな解決策だ。
- これ好き、これこそ私がLLMファーストOSとして思い描いていたものだ！要素を予測して巨大なドロップダウンを検索する認知負荷を下げるアイデアは、脳のいいところを刺激する。
**** ko
:PROPERTIES:
:LANG: ko
:END:
***** Title
자연어 인터페이스 사용을 중단하라
***** TLDR
LLM을 통한 자연어 인터페이스는 끔찍한 지연이 있다 - 종종 수십 초. 저자는 하이브리드 접근법을 제안한다: 구조화된 UI 요소(드롭다운, 체크박스)에 유연성을 위한 '기타' 탈출구를 사용하라. 양쪽의 장점만.
***** Take
YC 데모 데이의 절반을 울게 만들 핫 테이크: 아마 당신의 챗봇은 그냥 폼이어야 한다. 혁명적이지, 알아.
***** Comments
- 처리를 줄여 세상을 구하고 싶은 건 알겠지만, '자연어 인터페이스 사용 중단'은 지나치게 제한적이다. 20세기 인터랙티브 픽션은 의도적인 디자인으로 저부하 결정론적 자연어를 사용했다.
- 텍스트 인터페이스가 별로라고 생각하지만, 동시에 Claude Code가 설문지로 해결하는 방식이 좋다. 사용자로부터 가치 있는 맥락을 빠르게 얻는 가장 우아한 솔루션이다.
- 이거 좋아, 이게 내가 LLM 우선 OS로 상상해왔던 것이다! 요소를 예측하고 거대한 드롭다운 검색의 인지 부하를 줄이는 아이디어가 뇌의 좋은 곳을 자극한다.
**** es
:PROPERTIES:
:LANG: es
:END:
***** Title
Deja de usar interfaces de lenguaje natural
***** TLDR
Las interfaces de lenguaje natural vía LLMs tienen latencia terrible - a menudo decenas de segundos. El autor propone un enfoque híbrido: usar elementos de UI estructurados (desplegables, casillas) con una salida 'Otro' para flexibilidad. Lo mejor de ambos mundos.
***** Take
Opinión caliente que hará llorar a la mitad del YC Demo Day: tal vez tu chatbot debería ser solo un formulario. Revolucionario, lo sé.
***** Comments
- Entiendo que quieras salvar el mundo reduciendo procesamiento, pero 'deja de usar interfaces de lenguaje natural' es demasiado restrictivo. La ficción interactiva del siglo 20 usaba lenguaje natural determinístico con baja carga como diseño intencional.
- Creo que la interfaz de texto apesta, pero al mismo tiempo me gusta cómo Claude Code lo resuelve con cuestionarios. Es la solución más elegante para obtener contexto valioso de usuarios rápidamente.
- Me encanta esto, es lo que he estado imaginando como un OS LLM-first! La idea de tener elementos anticipados y reducir la carga cognitiva de buscar en una lista desplegable gigante me satisface mucho.
**** de
:PROPERTIES:
:LANG: de
:END:
***** Title
Hört auf, natürlichsprachliche Interfaces zu verwenden
***** TLDR
Natürlichsprachliche Interfaces über LLMs haben schreckliche Latenz - oft Dutzende Sekunden. Der Autor schlägt einen hybriden Ansatz vor: strukturierte UI-Elemente (Dropdowns, Checkboxen) mit einer 'Sonstiges'-Option für Flexibilität. Das Beste aus beiden Welten.
***** Take
Heißer Take, der die Hälfte des YC Demo Day zum Weinen bringen wird: Vielleicht sollte dein Chatbot einfach ein Formular sein. Revolutionär, ich weiß.
***** Comments
- Ich verstehe, dass du die Welt retten willst, indem du Verarbeitung reduzierst, aber 'hört auf, natürlichsprachliche Interfaces zu verwenden' ist zu restriktiv. Interaktive Fiktion aus dem 20. Jahrhundert verwendete deterministische natürliche Sprache mit niedriger Last als beabsichtigtes Design.
- Ich denke, Text-Interfaces sind schlecht, aber gleichzeitig gefällt mir, wie Claude Code das mit Fragebögen löst. Das ist die eleganteste Lösung, um schnell wertvollen Kontext von Nutzern zu bekommen.
- Liebe das, das ist es, was ich mir als LLM-first OS vorgestellt habe! Die Idee, Elemente vorwegzunehmen und die kognitive Last beim Durchsuchen einer riesigen Dropdown-Liste zu reduzieren, trifft einen guten Punkt in meinem Gehirn.