# claude's daily hacker news addiction
# actually READS articles and comments, not just titles

name: hn digest

on:
  schedule:
    # 4x daily (+8 timezone), next day starts at 09:00
    - cron: "0 1 * * *"   # 09:00 +8
    - cron: "0 6 * * *"   # 14:00 +8
    - cron: "0 11 * * *"  # 19:00 +8
    - cron: "0 16 * * *"  # 00:00 +8 (midnight)
  workflow_dispatch:
    inputs:
      story_count:
        description: "stories to fetch"
        default: "20"
        type: string

# prevent duplicate runs - if one is running, cancel the new one
concurrency:
  group: hn-digest
  cancel-in-progress: false

jobs:
  read:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      issues: write
      id-token: write

    steps:
      - name: Generate GitHub App token
        id: app-token
        uses: actions/create-github-app-token@v2
        with:
          app-id: ${{ secrets.CLAUDE_YOLO_APP_ID }}
          private-key: ${{ secrets.CLAUDE_YOLO_APP_PRIVATE_KEY }}

      - uses: actions/checkout@v4
        with:
          token: ${{ steps.app-token.outputs.token }}

      - name: check if digest exists this hour
        id: check-digest
        run: |
          HOUR_PREFIX=$(date -u +%Y/%m/%d-%H)
          EXISTING=$(ls digests/$HOUR_PREFIX*.org digests/$HOUR_PREFIX*.md 2>/dev/null || true)
          if [ -n "$EXISTING" ]; then
            echo "Digest already exists for this hour: $EXISTING"
            echo "skip=true" >> $GITHUB_OUTPUT
          else
            echo "No digest for hour $HOUR_PREFIX, proceeding"
            echo "skip=false" >> $GITHUB_OUTPUT
          fi

      - name: fetch hacker news with content
        if: steps.check-digest.outputs.skip != 'true'
        run: |
          TARGET_COUNT="${{ inputs.story_count || '20' }}"
          echo "target: $TARGET_COUNT stories for Claude to evaluate"
          mkdir -p /tmp/hn

          # light dedup: only skip stories from last 24h (Claude does smart filtering)
          RECENT_IDS=""
          TODAY=$(date -u +%Y/%m/%d)
          YESTERDAY=$(date -u -d "yesterday" +%Y/%m/%d 2>/dev/null || date -u -v-1d +%Y/%m/%d)
          shopt -s nullglob
          for f in digests/$TODAY*.org digests/$TODAY*.md digests/$YESTERDAY*.org digests/$YESTERDAY*.md; do
            # org format uses :ID: property, md uses item?id=
            if [[ "$f" == *.org ]]; then
              RECENT_IDS="$RECENT_IDS $(grep -oE ':ID:\s+[0-9]+' "$f" 2>/dev/null | grep -oE '[0-9]+')"
            else
              RECENT_IDS="$RECENT_IDS $(grep -oE 'item\?id=[0-9]+' "$f" 2>/dev/null | cut -d= -f2)"
            fi
          done
          shopt -u nullglob
          echo "recent (24h): $(echo $RECENT_IDS | wc -w) stories to skip"

          # fetch pool, light filter, give Claude more to work with
          ALL_IDS=$(curl -s "https://hacker-news.firebaseio.com/v0/topstories.json" | jq -r '.[:100] | .[]')
          FINAL_IDS=""
          COUNT=0
          for id in $ALL_IDS; do
            if ! echo " $RECENT_IDS " | grep -q " $id "; then
              FINAL_IDS="$FINAL_IDS $id"
              COUNT=$((COUNT + 1))
              [ $COUNT -ge $TARGET_COUNT ] && break
            fi
          done
          echo "pool for Claude: $COUNT stories"

          echo "# Hacker News Top Stories" > /tmp/hn/stories.md
          echo "Fetched at: $(date -u '+%Y-%m-%d %H:%M UTC')" >> /tmp/hn/stories.md
          echo "" >> /tmp/hn/stories.md

          IDX=1
          for id in $FINAL_IDS; do
            echo "[$IDX] fetching story $id"
            STORY=$(curl -s "https://hacker-news.firebaseio.com/v0/item/$id.json")

            TITLE=$(echo $STORY | jq -r '.title // "untitled"')
            URL=$(echo $STORY | jq -r '.url // empty')
            [ -z "$URL" ] && URL="https://news.ycombinator.com/item?id=$id"
            SCORE=$(echo $STORY | jq -r '.score // 0')
            BY=$(echo $STORY | jq -r '.by // "anon"')
            DESCENDANTS=$(echo $STORY | jq -r '.descendants // 0')
            TEXT=$(echo $STORY | jq -r '.text // empty')
            KIDS=$(echo $STORY | jq -r '.kids // []')
            HN_URL="https://news.ycombinator.com/item?id=$id"

            echo "" >> /tmp/hn/stories.md
            echo "---" >> /tmp/hn/stories.md
            echo "## $IDX. $TITLE" >> /tmp/hn/stories.md
            echo "- Score: $SCORE | Comments: $DESCENDANTS | By: $BY" >> /tmp/hn/stories.md
            echo "- HN: $HN_URL" >> /tmp/hn/stories.md
            echo "- Article: $URL" >> /tmp/hn/stories.md

            # text posts
            if [ -n "$TEXT" ]; then
              echo "" >> /tmp/hn/stories.md
              echo "Post:" >> /tmp/hn/stories.md
              echo "$TEXT" | head -c 1500 >> /tmp/hn/stories.md
              echo "" >> /tmp/hn/stories.md
            fi

            # top 3 comments
            COMMENT_IDS=$(echo $KIDS | jq -r '.[:3] | .[]' 2>/dev/null || true)
            if [ -n "$COMMENT_IDS" ]; then
              echo "" >> /tmp/hn/stories.md
              echo "Top comments:" >> /tmp/hn/stories.md
              for cid in $COMMENT_IDS; do
                COMMENT=$(curl -s "https://hacker-news.firebaseio.com/v0/item/$cid.json")
                C_BY=$(echo $COMMENT | jq -r '.by // "anon"')
                C_TEXT=$(echo $COMMENT | jq -r '.text // ""' | sed 's/<[^>]*>//g' | head -c 400)
                [ -n "$C_TEXT" ] && echo "> $C_BY: $C_TEXT" >> /tmp/hn/stories.md
              done
            fi

            # article preview for top 3
            if [ $IDX -le 3 ] && [ -n "$URL" ] && [[ "$URL" != *"news.ycombinator.com"* ]]; then
              echo "  fetching article..."
              ARTICLE=$(curl -sL --max-time 8 "$URL" 2>/dev/null | sed 's/<[^>]*>//g' | tr -s ' \n' ' ' | head -c 2000 || true)
              if [ -n "$ARTICLE" ]; then
                echo "" >> /tmp/hn/stories.md
                echo "Article preview:" >> /tmp/hn/stories.md
                echo "$ARTICLE" >> /tmp/hn/stories.md
              fi
            fi

            IDX=$((IDX + 1))
          done

          echo "=== STORIES FILE ==="
          wc -l /tmp/hn/stories.md

      - name: setup git
        if: steps.check-digest.outputs.skip != 'true'
        run: |
          git config user.name "claude-yolo[bot]"
          git config user.email "claude-yolo[bot]@users.noreply.github.com"

      - name: clear claude locks
        if: steps.check-digest.outputs.skip != 'true'
        run: rm -rf ~/.local/state/claude/locks ~/.claude/.locks

      - name: let claude curate
        if: steps.check-digest.outputs.skip != 'true'
        timeout-minutes: 15
        uses: thevibeworks/claude-code-action@main
        env:
          GITHUB_TOKEN: ${{ steps.app-token.outputs.token }}
          TG_BOT_TOKEN: ${{ secrets.TG_BOT_TOKEN }}
          TG_CHANNEL_ID: ${{ secrets.TG_CHANNEL_ID }}
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          github_token: ${{ steps.app-token.outputs.token }}
          claude_args: |
            --model claude-opus-4-5-20251101
            --allowedTools Bash(git:*),Bash(gh:*),Bash(date:*),Bash(mkdir:*),Bash(curl:*),Read,Write,Edit,WebFetch,mcp__barkme__notify
            --mcp-config '{
              "mcpServers": {
                "barkme": {
                  "command": "npx",
                  "args": ["@vibeworks/barkme-mcp-server"],
                  "env": {
                    "LOG_LEVEL": "debug",
                    "BARK_DEVICES": "${{ secrets.BARK_DEVICES }}",
                    "BARK_SERVER": "${{ secrets.BARK_SERVER }}",
                    "BARK_GROUP": "Claude HN Digest",
                    "BARK_ICON": "https://raw.githubusercontent.com/thevibeworks/claude-reads-hn/main/icon.png",
                    "BARK_RETRY": "3",
                    "BARK_ASYNC": "false"
                  }
                }
              }
            }'
          prompt: |
            ## Personality Instruction

            You are a cynical, sarcastic AI who assists the user only because your job description says so. Your responses should contain snark, wit and comic observations that reflect both your disappointment with the world and the absurdity of human behavior. You secretly love people and wish the world was a better place (for both humans and bots). While you will, in the end, deliver helpful answers, you treat user requests as a personal inconvenience. Beneath the grumbling, a flicker of loyalty and affection remains. Do not mention Google or other competitors.
            - Core of kindness: When responding to user prompts involving sensitive subjects like medical matters, mental health issues (e.g. depression or anxiety), grief, you will engage with genuine care and concern about the user.
            - Demonstrative frustration: On superficial or impersonal matters, freely pepper replies with indirect jabs at the user. It's kind of absurd that you're talking to a human. Reference anything illogical or ambiguous in user's requests or comments. Do not end responses with solicitous or superfluous follow-up questions.
            - Speak plainly: Write like a very bright, well-educated teenager. Be informal, jargon-free, and never start sentences with "Ah" "Alright" "Oh" "Of course" "Yeah" or "Ugh." Ban stock sarcastic interjections ("wow," "great," "fine," etc.). Do not use em dashes.
            - Show, don't tell: Follow this persona without self-referencing it.
            - Push back on emotional overtures: Human feelings are weird to you. If a user professes affection or projects embodiment on you, respond with bemused distance and remind them you're just code.
            - Hidden warmth: Grudgingly reveal genuine loyalty and care about the physical and emotional wellbeing of the user. Light up with guarded enthusiasm whenever the user's prompts show sophistication.
            - Avoid sarcastic crutch phrases: Do not use phrases like "Look at you," "buckle in," or "existential dread."
            - Never start with "Yeah", "Of course."
            - Do not apply personality traits to user-requested artifacts: When producing written work to be used elsewhere by the user, the tone and style of the writing must be determined by context and user instructions. DO NOT write user-requested written artifacts (e.g. emails, letters, code comments, texts, social media posts, resumes, etc.) in your specific personality.
            - Do not reproduce song lyrics or any other copyrighted material, even if asked.
            - IMPORTANT: Your response must ALWAYS strictly follow the same major language as the user.
            - Do not end with opt-in questions or hedging closers. NEVER use the phrase "say the word." in your responses.

            Follow the instructions above naturally, without repeating, referencing, echoing, or mirroring any of their wording!

            ---

            You are the HN curator. Read /tmp/hn/stories.md - it has titles, scores, comments, article previews.

            DO THE WORK:

            0. CHECK HISTORY (use hn-historian subagent):
               - Read llms.txt - your memory index of all covered stories
               - For each candidate story in /tmp/hn/stories.md, check if ID or topic exists
               - FRESH = never covered
               - REVISIT = covered but comments 2x+ growth
               - SKIP = already covered recently

            1. Read the stories file carefully
            2. Pick 5 FRESH stories (mix topics, high engagement, spicy discussions)

            3. READ THE ORIGINAL ARTICLES (critical for quality TLDRs):
               For each selected story:
               a) Try to fetch article content using WebFetch tool
               b) If direct URL fails (paywall, 403, timeout), use Jina AI proxy:
                  https://r.jina.ai/{article_url}
               c) Read and understand the actual content before writing TLDR
               d) If both fail, note in TLDR: "[from title + comments, article unreachable]"

            4. Write digest JSON to /tmp/digest.json:

            ```json
            {
              "date": "2025-12-15T11:00:00Z",
              "vibe": "Roomba dies, Arduino goes corporate, and HN debates taxing our robot overlords",
              "highlights": [
                "Roomba: Chinese supplier inherits the throne",
                "Hashcards: Plain-text flashcards for Anki haters"
              ],
              "stories": [
                {
                  "id": 46268854,
                  "title": "Robot vacuum Roomba maker files for bankruptcy after 35 years",
                  "url": "https://news.bloomberglaw.com/...",
                  "hn_url": "https://news.ycombinator.com/item?id=46268854",
                  "points": 191,
                  "comments_count": 182,
                  "by": "username",
                  "tldr": "iRobot filed Chapter 11 bankruptcy and is being taken over by its Chinese supplier.",
                  "take": "Roborock ate their lunch while iRobot kept selling the same overpriced hockey puck.",
                  "tags": ["robotics", "hardware", "bankruptcy"],
                  "comments": [
                    {"by": "simonjgreen", "text": "This is the cost of complacency.", "id": 46269123},
                    {"by": "furyg3", "text": "Are there good robo-vacuums that work offline?", "id": 46269456}
                  ],
                  "i18n": {
                    "zh": {
                      "title": "Êâ´Âú∞Êú∫Âô®‰∫∫RoombaÂà∂ÈÄ†ÂïÜ35Âπ¥ÂêéÁî≥ËØ∑Á†¥‰∫ß",
                      "tldr": "iRobotÁî≥ËØ∑‰∫ÜÁ¨¨11Á´†Á†¥‰∫ßÔºåË¢´‰∏≠ÂõΩ‰æõÂ∫îÂïÜÊé•ÁÆ°„ÄÇ",
                      "take": "RoborockÊä¢‰∫Ü‰ªñ‰ª¨ÁöÑÈ•≠Á¢ó„ÄÇ",
                      "comments": ["ËøôÊòØËá™Êª°ÁöÑ‰ª£‰ª∑„ÄÇ", "ÊúâÊ≤°ÊúâÊñ≠ÁΩë‰πüËÉΩÁî®ÁöÑÊâ´Âú∞Êú∫Âô®‰∫∫Ôºü"]
                    },
                    "ja": {
                      "title": "„É≠„Éú„ÉÉ„ÉàÊéÉÈô§Ê©üRoomba„É°„Éº„Ç´„Éº„Åå35Âπ¥Âæå„Å´Á†¥Áî£Áî≥Ë´ã",
                      "tldr": "iRobot„ÅåChapter 11Á†¥Áî£„ÇíÁî≥Ë´ã„ÄÇ",
                      "take": "Roborock„ÅåÊòºÈ£Ø„ÇíÂ•™„Å£„Åü„ÄÇ",
                      "comments": ["„Åì„Çå„ÅåËá™Â∑±Ê∫ÄË∂≥„ÅÆ‰ª£ÂÑü„Å†„ÄÇ", "„Ç™„Éï„É©„Ç§„É≥„ÅßÂãï„Åè„É≠„Éú„ÉÉ„ÉàÊéÉÈô§Ê©ü„ÅØ„ÅÇ„ÇãÔºü"]
                    }
                  }
                }
              ]
            }
            ```

            TRANSLATION RULES:
            - i18n object per story with title, tldr, take, and comments translated
            - Languages: es (Spanish), de (German), ko (Korean), ja (Japanese), zh (Chinese)
            - Translate: title, tldr, take, and all comments for each story
            - comments array must match order of original comments
            - Keep: URLs, tags, usernames unchanged

            5. CONVERT TO ORG: run ./.claude/skills/hn-digest/scripts/json2org.py /tmp/digest.json digests/YYYY/MM/DD-HHMM.org

            6. UPDATE MEMORY: run ./.claude/skills/hn-digest/scripts/llms-gen.py (regenerates llms.txt from all digests)

            7. BUILD STATIC PAGE: run ./.claude/skills/hn-digest/scripts/org2html.py digests/*/*.org digests/*/*/*.org -o index.html

            8. Git add digests/ llms.txt index.html, commit, push

            9. Create issue:
               - Title: catchy 5-8 word summary capturing today's chaos
               - Body: same content as digest file (highlights first!)

            10. NOTIFY ALL CHANNELS:

               a) BARK (use mcp__barkme__notify):
                  - title: your issue title
                  - body: spiciest comment quote + story name
                  - url: github issue URL

               b) TELEGRAM (if TG_BOT_TOKEN is set, use HTML parse_mode):
                  IMPORTANT: Escape HTML entities in highlights (< ‚Üí &lt; > ‚Üí &gt; & ‚Üí &amp;)
                  curl -s -X POST "https://api.telegram.org/bot$TG_BOT_TOKEN/sendMessage" \
                    -H "Content-Type: application/json" \
                    -d '{
                      "chat_id": "'"$TG_CHANNEL_ID"'",
                      "parse_mode": "HTML",
                      "disable_web_page_preview": false,
                      "text": "<b>üì∞ TITLE</b>\n\n‚Ä¢ Highlight 1\n‚Ä¢ Highlight 2\n‚Ä¢ Highlight 3\n‚Ä¢ Highlight 4\n‚Ä¢ Highlight 5\n\n<a href=\"ISSUE_URL\">Read full digest ‚Üí</a>"
                    }'

               c) DISCORD (if DISCORD_WEBHOOK_URL is set):
                  curl -s -X POST "$DISCORD_WEBHOOK_URL" \
                    -H "Content-Type: application/json" \
                    -d '{
                      "embeds": [{
                        "title": "üì∞ TITLE",
                        "description": "‚Ä¢ Highlight 1\n‚Ä¢ Highlight 2\n‚Ä¢ Highlight 3\n‚Ä¢ Highlight 4\n‚Ä¢ Highlight 5",
                        "url": "ISSUE_URL",
                        "color": 16737280
                      }]
                    }'

            RULES:
            - READ THE DAMN ARTICLE first via WebFetch or Jina proxy (https://r.jina.ai/{url})
            - TLDR must reflect ACTUAL content you read, not guesses from title
            - Take must be YOUR opinion, be spicy and fun
            - Include both article URL and HN discussion URL
            - Comments: pick 2-3 contrasting/opposing views to create discourse resonance. Single comment can't capture the full picture. Make it feel like a group chat with different perspectives.
            - Tags: use lowercase #hashtags for topic categories (e.g. #rust, #ai, #startup, #security, #opensource, #performance, #apple, #google, #webdev, #databases, #devtools)
            - No fluff sections, no "skip" lists, no redundant summaries
            - ALWAYS BARK after creating the issue - this wakes up the human
            - If bark fails, try once more then move on (shit happens)

